# -*- coding: utf-8 -*-
# FacialRecognitionCNN.ipynb

# Automatically generated by Colab.

# Original file is located at
#   https://colab.research.google.com/drive/1pYzKojGBTQbrOcxtYqiTDi-TraNGZbZ3

# Data Preparation

# Imports

import torch
import torchvision

#Getting Data

data_dir = "./Celebrity Faces Dataset/5 Main People"

# Random Seed

import numpy as np
torch.manual_seed(42)
np.random.seed(42)

# Formatting the Dataset

from torchvision import datasets, transforms
#resize all images
height = 160
length = 160

#Note we only want to transform the training data, not the testing data
train_transform = transforms.Compose([
    transforms.RandomRotation(10),      # rotate +/- 10 degrees
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(brightness = 0.1, contrast = 0.1, saturation = 0.1, hue = 0.1), #randomly selects brightness between [0.9,1.1]
    transforms.Resize((height, length)),
    transforms.ToTensor(),
    transforms.Normalize(mean = (0.5,0.5,0.5), std = (0.5,0.5,0.5)) # normalizes from [0,1] --> [-1,1]
])

test_transform = transforms.Compose([
    transforms.Resize((height, length)),
    transforms.ToTensor(),
    transforms.Normalize(mean = (0.5,0.5,0.5), std = (0.5,0.5,0.5))
])

dataset = datasets.ImageFolder(root=data_dir, transform = None)

classes = dataset.find_classes(directory = data_dir)[0]

print(classes)

# Train/Validation/Test Split

from torch.utils.data import random_split
import copy

total_size = len(dataset)  # 70/15/15 Trin/Validation/Test split
train_size = int(0.7 * total_size)
val_size = int(0.15 * total_size)
test_size = total_size - train_size - val_size

train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])

augmented_train_set = copy.deepcopy(train_set)

augmented_train_set.dataset.transform = train_transform

train_set.dataset.transform = test_transform


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# Displaying an Image

import matplotlib.pyplot as plt
import numpy as np

def imshow(img):
    img = img / 2 + 0.5
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

# Running Example

# demo_img_idx = 5
# demo_img = augmented_train_set[demo_img_idx][0]
#  imshow(demo_img)
# test_label = augmented_train_set[demo_img_idx][1]
# print("Ground Truth Label: ", classes[test_label])

# Model Definition

# Architecture 1 - Simple Linear

import torch.nn as nn
import torch.nn.functional as F

class SimpleLinear(nn.Module):
    def __init__(self, num_classes):
        super().__init__()

        flat_feats = height * length * 3

        self.fc1 = nn.Linear(flat_feats, 120)
        self.fc2 = nn.Linear(120,        84)
        self.fc3 = nn.Linear(84,         20)
        self.fc4 = nn.Linear(20,  num_classes)


    def forward(self, x):

        x = torch.flatten(x, 1) # flatten all dimensions except batch

        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = F.relu(self.fc3(x))
        x = self.fc4(x)


        return x

# Architecture 1 - Complex CNN

import torch.nn as nn
import torch.nn.functional as F

class ComplexArchitectureCNN(nn.Module):
    def __init__(self, num_classes):
        super().__init__()

        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 6, kernel_size = 3, padding = 1, stride = 1)

        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)

        self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 16, kernel_size = 3, padding = 1, stride = 1)

        h_out = height // 2 // 2
        l_out = length // 2 // 2
        flat_feats = 16 * h_out * l_out


        self.fc1 = nn.Linear(flat_feats, 120)
        self.fc2 = nn.Linear(120,        84)
        self.fc3 = nn.Linear(84,         20)
        self.fc4 = nn.Linear(20,  num_classes)

        self.dropout = nn.Dropout(p = 0)


    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))

        x = torch.flatten(x, 1) # flatten all dimensions except batch

        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = F.relu(self.fc2(x))
        x = self.dropout(x)
        x = F.relu(self.fc3(x))
        x = self.dropout(x)
        x = self.fc4(x)


        return x

# Criterion

criterion = nn.CrossEntropyLoss() #Cross Entropy (MLE assuming Categorical Distribution)

# Computing Accuracy

def compute_accuracy(model, data_loader):
  correct = 0
  total = 0

  model.eval()
  with torch.no_grad():
      for images, labels in data_loader:
          images = images.to(device)
          labels = labels.to(device)

          outputs = model(images)

          _, predicted = torch.max(outputs, 1)
          total += labels.size(0)
          correct += (predicted == labels).sum().item()
  accuracy = correct / total * 100
  return accuracy

# Model Training

from torch.utils.data import DataLoader
import torch.optim as optim

def train_model(batch_size, epochs, lr, weight_decay, n_classes, architecture = 'complex'):
    val_loader = DataLoader(val_set, batch_size = 512)
    val_accuracy = 0

    if(architecture == 'simple'):
      model = SimpleLinear(n_classes)
      optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay = weight_decay)
      train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle=True)


    elif(architecture == 'complex'):
      model = ComplexArchitectureCNN(n_classes)
      optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay = weight_decay)
      scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer,
        mode='max',        # because we monitor validation ACC (higher is better)
        factor=0.1,        # multiply LR by this on plateau
        patience=3,        # wait this many epochs with no improvement
        min_lr=1e-6        # lower bound on LR
      )
      train_loader = torch.utils.data.DataLoader(augmented_train_set, batch_size = batch_size, shuffle=True)



    model = model.to(device)


    for epoch in range(1, epochs + 1):
      for images, labels in train_loader:
          images = images.to(device)
          labels = labels.to(device)


          optimizer.zero_grad()

          outputs = model.forward(images)
          loss = criterion(outputs, labels)
          loss.backward()
          optimizer.step()
          print("Loss:", round(loss.item(), 3))

      val_accuracy = compute_accuracy(model, val_loader)
      print("Epoch:", epoch, "Validation Accuracy:", round(val_accuracy, 3), '%' )


      if(architecture == 'complex'):
        scheduler.step(val_accuracy)

    return model

def get_model():
    batch_size = 128
    epoch = 15
    lr = 0.001
    weight_decay = 0.001
    n_classes = len(classes)
    model = train_model(batch_size, epoch, lr, weight_decay, n_classes, architecture = 'complex')
    return model
# Testing the Model


#Main: 
if __name__ == "__main__":
    #do some testing here
    brad_pert = './PerturbedFolder'

    transfer_dataset = datasets.ImageFolder(root=brad_pert, transform = test_transform)

    print(classes)

    print("Original label at #99:", transfer_dataset[99][1])

    # 2. override _all_ labels in the `samples` list
    for i, (path, _) in enumerate(transfer_dataset.samples):
        transfer_dataset.samples[i] = (path, 1)

    # 3. verify
    print("New label at #99:", transfer_dataset[99][1])

    # 4. now you can create your loader
    transfer_loader = DataLoader(transfer_dataset, batch_size=1, shuffle=True, num_workers=4)

    model = get_model()

    transfer_accuracy = compute_accuracy(model, transfer_loader)

    print("transfer_acc: ", transfer_accuracy)










